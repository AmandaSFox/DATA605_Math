---
title: "Assignment 1 Question 4"
format: html
---

```{r libraries}
library(tidyverse)
library(abind)
library(imager)
library(FactoMineR)
library(reticulate)
```


## Eigenfaces from the LFW (Labeled Faces in the Wild) Dataset

#### 1. Download the data

I used the suggested approach of a Python script (lfw module in sklearn library) to download the dataset and extracted the images component to a numpy file. I used no resizing and color=True to set up for our preprocessing step below.

```{python echo=true eval=false}

from sklearn.datasets import fetch_lfw_people
import numpy as np

# download full dataset
lfw_people = fetch_lfw_people(min_faces_per_person=1, resize=None, color=True)

# save images file as numpy array
images = lfw_people.images
np.save("lfw_image_arrays.npy", images)

```

#### 2. Preprocess the images
Convert the images to grayscale and resize them to a smaller size (e.g., 64x64) to reduce computational complexity. Flatten each image into a vector.  

In this challenging step, I learned about the images package, as well as how and why we need to move between images objects, arrays, and finally vectors to accomplish all of our required processing. 

I did get tripped up after successfully using an images package function to grayscale the whole array of images at once: trying to replicate that logic to resize the whole array definitely did not work and I needed to resize each image via looping. Flattening the array into vectors and storing in a matrix was straightforward with more looping.

```{r faces}

#Load data with numpy. Verify 13233 images

np <- import("numpy")
#lfw_data <- np$load("lfw_image_arrays.npy") #my local storage 

# ------------
# Download file copy stored in azure blob instead of local storage: 
# ------------
sas_url <- "https://foxdata605.blob.core.windows.net/assignment-1/lfw_image_arrays.npy?sp=r&st=2025-02-22T03:56:35Z&se=2025-05-31T10:56:35Z&spr=https&sv=2022-11-02&sr=b&sig=320CmhkOOz8bkbHRJPQ0Z4nbvJo2oHHYlWP90186FRI%3D" 

options(timeout = 600) 
download.file(sas_url, "lfw_image_arrays.npy")
lfw_data <- np$load("lfw_image_arrays.npy") 

# ------------
# Continue processing with downloaded data copy: 
# ------------
dim(lfw_data)

# Show the first image in original form
first_image <- lfw_data[1,,,]
first_image_cimg <- as.cimg(first_image)
plot(first_image_cimg)

# Convert to an imager object and grayscale
lfw_cimg <- as.cimg(lfw_data)
grayscale_lfw_cimg <- grayscale(lfw_cimg)

# Convert back to an array
grayscale_lfw <- as.array(grayscale_lfw_cimg[,,,1]) #select first channel
dim(grayscale_lfw)

# View first grayscaled image
grayscale_image <- grayscale_lfw[1,,]
grayscale_image_cimg <- as.cimg(grayscale_image)
plot(first_resized_grayscale_image_cimg, main = "First Grayscale Image (Optimized)")

# Create array to store resized images
count_images <- dim(grayscale_lfw)[1]
resized_grayscale_lfw <- array(0, dim = c(count_images, 64, 48))

# Loop 
for (i in 1:count_images) {
  # Convert to cimg
  image_cimg <- as.cimg(grayscale_lfw[i,,])  
  # Resize
  resized_image_cimg <- resize(image_cimg, 64, 48)  # Resize to 64x48
  # Convert back to array
  resized_grayscale_lfw[i,,] <- as.array(resized_image_cimg[,,,1])  
}

# Check the dimensions
dim(resized_grayscale_lfw)

# View first resized image
resized_grayscale_image <- resized_grayscale_lfw[1,,]
resized_grayscale_image_cimg <- as.cimg(resized_grayscale_image)
plot(first_resized_grayscale_image_cimg, main = "First Resized Grayscale Image (Optimized)")

# Flatten each image into vector and store as matrix

matrix_lfw <- matrix(NA, 
                        nrow = dim(resized_grayscale_lfw)[1], 
                        ncol = 64*48)

for (i in 1:dim(resized_grayscale_lfw)[1]) {
  matrix_lfw[i, ] <- as.vector(resized_grayscale_lfw[i,,])
}

# Check the new dimensions
dim(matrix_lfw)

```

#### 3. Apply PCA
Compute the PCA on the flattened images. Determine the number of principal components required to account for 80% of the variability.  

In this step, I learned about the outputs of the simple base R prcomp function and used the sdev component to find the % variation explained by each principal component.

**40** principal components account for 80% of the variability. 

```{r faces_pca}
# Compute PCA using base R function 
pca_result <- prcomp(matrix_lfw, center = TRUE, scale. = TRUE)

# Compute cumulative variance
explained_variance <- pca_result$sdev^2 / sum(pca_result$sdev^2)
cumulative_variance <- cumsum(explained_variance)
components_80 <- which(cumulative_variance >= 0.80)[1]
components_80

```
#### 4. Visualize Eigenfaces 
Visualize the first few eigenfaces (principal components) and discuss their significance. Reconstruct some images using the computed eigenfaces and compare them with the original images.

The rotation component of the PCA output is a matrix of eigenvectors. Each column is a PCA, arranged in order of highest to lowest variation, and each row is a pixel.

In this facial recognition exercise, a PCA is an eigenface, or a component that makes up face images. 

```{r faces_eigen}

# top four pcas
num_eigenfaces <- 4
eigenfaces <- pca_result$rotation[, 1:num_eigenfaces]
dim(eigenfaces)

# Loop through the first few principal components
for (i in 1:num_eigenfaces) {
  eigenface_matrix <- matrix(pca_result$rotation[, i], 
                             nrow = 64, 
                             ncol = 48)  # Reshape vector
  eigenface_cimg <- as.cimg(eigenface_matrix)  # Convert to cimg object
  plot(eigenface_cimg, main = paste("Eigenface", i))
}

```

For the final reconstruction, I picked images # 1, 500, and 1000 from the grayscale/resized data and used the top 40 PCAs (which accounted for 80% of the variation in the dataset). Online resources were again very helpful in this step and I learned a lot about this process through this exercise.

```{r eigen2}

#---------
# Reconstructing with Eigenfaces
#---------

# Images to reconstruct
image_indices <- c(1, 50, 100)

# Initialize a list to store reconstructed images
reconstructed_images <- list()

for (i in seq_along(image_indices)) {
  img_idx <- image_indices[i]
  test_image <- matrix_lfw[img_idx, ]
  # get principal components
  projected_coefficients <- test_image %*% pca_result$rotation[, 1:40]
  # Reconstruct the image
  reconstruction <- projected_coefficients %*% t(pca_result$rotation[, 1:40])
  
  # Add the mean image back
  reconstructed_image <- reconstruction + pca_result$center
  
  # Reshape into 64x48 image format and store it
  reconstructed_images[[i]] <- matrix(reconstructed_image, nrow = 64, ncol = 48)
}

#---------
# Plots
#---------

par(mfrow = c(2, 3))

for (i in seq_along(image_indices)) {
  img_idx <- image_indices[i]
  # Plot Original Image
  original_matrix <- matrix(matrix_lfw[img_idx, ], nrow = 64, ncol = 48)
  original_cimg <- as.cimg(original_matrix)
  plot(original_cimg, main = paste("Original Image", img_idx))
  # Plot Reconstructed Image (40 PCs)
  reconstructed_cimg <- as.cimg(reconstructed_images[[i]])
  plot(reconstructed_cimg, main = paste("Reconstructed (40 PCs)", img_idx))
}

```